{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. The Value of Domain Knowledge\n",
    "Compiled by [Morgan Williams](mailto:morgan.williams@csiro.au) for C3DIS 2018 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, much of the content has concerned more applied chemistry and statistics. Here we touch on some valuable aspects of domain-specific knowledge relevant for geochemical data analysis. Additionally, we examine the potential for data to be used as a validation method for existing domain methods and knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"All science is either physics or stamp collecting\"* **Ernest Rutherford**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geologists, like most other scientists which conduct observation-based investigations, have a habit of 'stamp collecting'. Methods to classify rocks provide geologists with a vocabulary with which to discuss and focus their investigations, but models developed in the past are rarely subjected to continued testing and refinement. Geological samples and derived geochemical data are commonly stored with pre-derived classifications. Here we derive these from their models, and compare i) the quality of database classification information, and ii) the potential relevance of historical classification models in an era which is no longer data-limited.\n",
    "\n",
    "Modern databases provide a foundation for i) testing historical classification schemes and ii) implementing new classification schemes based on inherent data relationships and statistical divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from compositions import *\n",
    "from geochem import *\n",
    "from classification import Geochemistry\n",
    "from alteration import *\n",
    "from datasource import load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df('EarthChemGlobal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = Geochemistry.TAS()\n",
    "classnames = cm.clsf.fclasses + ['none']\n",
    "df.TotalAlkali = df.Na2O + df.K2O\n",
    "df['TAS'] = cm.classify(df).astype('category')\n",
    "df['TAScolors'] = df['TAS'].map(lambda x: classnames.index(x)) # Use the index in the list for a simple colormap\n",
    "df['TASRock'] = df['TAS'].map(lambda x: cm.clsf.fields.get(x,{'names': ['N/A']}).get('names')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can assess a range of questions regarding the data quality, and potentially the quality of classification methods.\n",
    "\n",
    "Note: The following cell takes a while to run - plotting 100s of thousands of points is not matplotlib's best quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(12, 12), sharex=True, sharey=True)\n",
    "ax=ax.flat\n",
    "for a in ax:\n",
    "    a.set_ylabel('$Na_2O + K_2O$')\n",
    "    a.set_xlabel('$SiO_2$')\n",
    "    cm.add_to_axes(a, alpha=0.2, edgecolor='k', linewidth=1, zorder=-1)\n",
    "\n",
    "filters = []\n",
    "for rockname in ['BASALT', 'RHYOLITE']:\n",
    "    filters.append((rockname, (df.loc[:, 'RockName'] == rockname) & (df.loc[:, 'Material'] == 'IGNEOUS')))\n",
    "    \n",
    "for composition in ['ULTRAMAFIC', 'FELSIC']:\n",
    "    filters.append((composition, (df.loc[:, 'Composition'] == composition) & (df.loc[:, 'Material'] == 'IGNEOUS')))\n",
    "    \n",
    "for ty in ['PLUTONIC', 'VOLCANIC']:\n",
    "    filters.append((ty, (df.loc[:, 'Type'] == ty) & (df.loc[:, 'Material'] == 'IGNEOUS'))) \n",
    "    \n",
    "for ix, (name, filt) in enumerate(filters):\n",
    "    ax[ix].annotate(name, xy=(0.1, 0.9), ha='left', xycoords=ax[ix].transAxes)\n",
    "    ax[ix].scatter(df.loc[filt, 'SiO2'],\n",
    "                   df.loc[filt, 'TotalAlkali'],\n",
    "                   c=df.loc[filt, 'TAScolors'],\n",
    "                   alpha=0.5, marker='D', s=8, cmap='tab20c')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give me a Map: Incorporating Reference Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Communicating the significance of data in a broader context requires some reference frame. This is a feature commonly addressed throughout all scientific disciplines, and geologists in general do this relatively well.\n",
    "\n",
    "The simplest case of such a reference frame in geochemistry is the composition of a known reference material - which could be a mineral, a particular rock type or our estimate for the average composition of the solar system. While such reference frames are present throughout the literature, they are rarely baked into analysis tools, and the basic information required to reproduce them is commonly required to be reconstructed manually.\n",
    "\n",
    "Here we attempt to begin construction of a few reference frames for different purposes. The first is general orientation - where do our compositions lie relative to others (e.g. mineral compositions, average compositions globally). To some extent, the classifications mentioned above can help with this. The second is to have a reference frame to illustrate the potential effects of a specific process (e.g. if I mixed two compositions, what would the range of expected compositions look like?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond Data QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlling data quality is the first step, but for various reasons specific samples can be unsuitable for investigating specific geochemical features or processes. Here we note a group of simple alteration proxies which can be used to create data-derived features for use in data filtering/classification.\n",
    "\n",
    "These proxies are intended to encompase the effects of chemical alteration - most are tied to specific mineralogical weathering processes. As a first pass we can visualise the distribution of these proxies across the database samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = 'FeOT'\n",
    "alteration_index_functions = [CIA, CIW, PIA, SAR, SiTiIndex, WIP]\n",
    "lenfs = len(alteration_index_functions)\n",
    "plotswide=3\n",
    "unit = 2\n",
    "fig, ax = plt.subplots(lenfs%plotswide+lenfs//plotswide, plotswide,\n",
    "                       figsize=((1+plotswide) * unit, (1 + lenfs//plotswide) * unit),\n",
    "                       sharex=True)\n",
    "ax = ax.flat\n",
    "major_components = [i for i in df.columns if i in common_oxides(output=str)]\n",
    "for ix, f in enumerate(alteration_index_functions):\n",
    "    fname = f.__name__\n",
    "    if not fname in df.columns:\n",
    "        df[fname] = f(to_molecular(df.loc[:, major_components]))\n",
    "    \n",
    "    filt = (df.Material == 'IGNEOUS')\n",
    "    ax[ix].annotate(fname, xy=(0.9, 0.9), ha='right', xycoords=ax[ix].transAxes)\n",
    "    ax[ix].scatter(df.loc[filt, xvar], df.loc[filt, fname], alpha=0.01, color='0.5')\n",
    "    ax[ix].set_xlabel(xvar)\n",
    "    ax[ix].set_ylabel(fname)\n",
    "    \n",
    "ax[2].set_ylim((-100, 100))\n",
    "ax[3].set_ylim((0, 100))\n",
    "ax[0].set_xlim((0, 30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
